# Skrypt do scrapowania stron internetowych

Ten projekt zawiera skrypt Pythona do scrapowania stron internetowych, umożliwiający użytkownikom ekstrakcję treści z dowolnych stron internetowych z wykorzystaniem niestandardowych wzorców URL i tagów HTML.

## urlcrawler.exe -> [pobierz](https://github.com/JRadomyski/URL-Scraper/blob/main/dist/url_scraper.exe)
Następnie kliknij `ctrl` + `shift` + `s` albo zrób to ręcznie

### Krok 1: Wejdź do katalogu `dist`
![dist](readme_assets/dist.png)
### Krok 2: Pobierz plik exe
![exe](readme_assets/exe.png)
### Krok 3: Omiń defendera - wejdź w `więcej informacji`, a następnie `uruchom mimo to`
![def](readme_assets/defender.png)
![def2](readme_assets/defender2.png)
### Krok 4: Postępuj zgodnie z instrukcją
![exe2](readme_assets/exe2.png)
![exe3](readme_assets/exe3.png)
### Krok 5: w folderze `outputs` zapisane są wyniki scrapeowania
![output](readme_assets/output.png)
### Jeśli napotkasz problemy podczas zapisu danych do pliku, sprawdź:

1. Czy folder `outputs` istnieje i czy masz do niego odpowiednie uprawnienia.
2. Czy skrypt poprawnie zbiera dane (możesz dodać wydruk do konsoli).
3. Czy ścieżka do zapisu pliku jest poprawna.
4. Czy występują jakieś błędy podczas zapisu (sprawdź komunikaty błędów).

